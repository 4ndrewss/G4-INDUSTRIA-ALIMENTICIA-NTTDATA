{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9e5d256b-2230-4081-afa5-6ace5bc3472d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import ( col, to_date, year, lit, when, trim, regexp_replace,date_format)\n",
    "from pyspark.sql.types import ( IntegerType, DoubleType, StringType, DateType )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4682e633-0cd1-4be2-8166-85fd4bf456a3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "df_vendas = spark.sql(\"SELECT * FROM classes.bronze.exceis_vendas\")\n",
    "\n",
    "# 2. Carregar tabela de Produtos da camada Bronze\n",
    "df_produto = spark.sql(\"SELECT * FROM classes.bronze.exceis_produto\")\n",
    "\n",
    "# Opcional: Exibir as primeiras linhas para confirmar que carregou corretamente\n",
    "print(\"Visualizando Vendas:\")\n",
    "display(df_vendas)\n",
    "\n",
    "print(\"Visualizando Produtos:\")\n",
    "display(df_produto)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "84a213d4-58aa-4319-9160-e9a2656cce44",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d32804d2-ca90-492e-9c24-926effdaa61f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_estoque = spark.sql(\"select * from classes.bronze.exceis_estoque\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c53aa46d-827e-43c8-a635-dbb404bad505",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%python\n",
    "from pyspark.sql.functions import col, to_date\n",
    "\n",
    "# Lê a tabela Bronze\n",
    "df_estoque = spark.table(\"classes.bronze.exceis_estoque\")\n",
    "\n",
    "# CORREÇÃO: Removemos o 'date_format'. \n",
    "# O 'to_date' já converte para o tipo Data (padrão yyyy-MM-dd).\n",
    "# O Databricks sabe lidar com isso perfeitamente.\n",
    "\n",
    "df_estoque = df_estoque.withColumn(\n",
    "    \"data_validade\",\n",
    "    to_date(col(\"data_validade\"), \"dd/MM/yyyy\")\n",
    ").withColumn(\n",
    "    \"data_fabricacao\",\n",
    "    to_date(col(\"data_fabricacao\"), \"dd/MM/yyyy\")\n",
    ")\n",
    "\n",
    "display(df_estoque)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "16071936-42c6-4777-adca-50347ca4c6cf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%python\n",
    "from pyspark.sql.functions import col, to_date\n",
    "\n",
    "df_estoque = spark.table(\n",
    "    \"classes.bronze.exceis_estoque\"\n",
    ")\n",
    "\n",
    "# CORREÇÃO: Removemos o date_format.\n",
    "# Agora convertemos direto para TIPO DATA (DateType).\n",
    "# Isso permite que você ordene e faça contas na camada Gold.\n",
    "df_estoque = df_estoque.withColumn(\n",
    "    \"data_validade\",\n",
    "    to_date(col(\"data_validade\"), \"dd/MM/yyyy\")\n",
    ").withColumn(\n",
    "    \"data_fabricacao\",\n",
    "    to_date(col(\"data_fabricacao\"), \"dd/MM/yyyy\")\n",
    ")\n",
    "\n",
    "display(df_estoque)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "80db8357-0b81-4739-a197-753cd3ebdb95",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_vendas = spark.sql(\"select * from classes.bronze.exceis_vendas\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fdfe2b38-0559-4afb-868c-66c8cc4108d5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(df_vendas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e796ef72-f3c2-4ad7-b5da-0ad8f18bacd6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, to_date, trim\n",
    "\n",
    "df_vendas = spark.table(\"classes.bronze.exceis_vendas\")\n",
    "\n",
    "df_vendas = df_vendas.withColumn(\n",
    "    \"data_validade\",\n",
    "    to_date(col(\"data_validade\"), \"dd/MM/yyyy\")\n",
    ").withColumn(\n",
    "    \"data_fabricacao\",\n",
    "    to_date(col(\"data_fabricacao\"), \"dd/MM/yyyy\")\n",
    ").withColumn(\n",
    "    \"nome_produto\", \n",
    "    trim(col(\"nome_produto\"))\n",
    ")\n",
    "\n",
    "display(df_vendas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5fa1c0ef-9fe8-4acc-8ac7-c85c63faf791",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%python\n",
    "from pyspark.sql.functions import col, to_date\n",
    "\n",
    "# 1. Carrega a tabela Bronze\n",
    "df_estoque = spark.table(\"classes.bronze.exceis_estoque\")\n",
    "\n",
    "# 2. Converte as colunas de texto para DATA real\n",
    "# Ajustei o formato para \"dd/MM/yyyy\" para casar com o seu CSV original\n",
    "df_estoque = df_estoque.withColumn(\n",
    "    \"data_validade\",\n",
    "    to_date(col(\"data_validade\"), \"dd/MM/yyyy\")\n",
    ").withColumn(\n",
    "    \"data_fabricacao\",\n",
    "    to_date(col(\"data_fabricacao\"), \"dd/MM/yyyy\")\n",
    ")\n",
    "\n",
    "# 3. Exibe o resultado para você conferir\n",
    "display(df_estoque)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "240dde19-3fbd-4ce2-b710-e9244a6dbc3b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%python\n",
    "display(df_estoque)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8854f539-e118-442c-8433-934c0125c5cc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_estoque.select(\"nome_produto\").distinct().show(200, False)\n",
    "df_estoque.select(\"nome_subproduto\").distinct().show(200, False)\n",
    "df_estoque.select(\"local_fabricacao\").distinct().show(200, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2c84c71d-81ce-437b-8294-e459103d4fa4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import trim, col\n",
    "\n",
    "df_estoque = df_estoque.withColumn(\"nome_produto\", trim(col(\"nome_produto\")))\n",
    "df_estoque = df_estoque.withColumn(\"nome_subproduto\", trim(col(\"nome_subproduto\")))\n",
    "df_estoque = df_estoque.withColumn(\"local_fabricacao\", trim(col(\"local_fabricacao\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e7484b64-5c83-43a4-a5f8-d7f9046749f5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_estoque.filter(\n",
    "    (col(\"nome_produto\") != trim(col(\"nome_produto\"))) |\n",
    "    (col(\"nome_subproduto\") != trim(col(\"nome_subproduto\"))) |\n",
    "    (col(\"local_fabricacao\") != trim(col(\"local_fabricacao\")))\n",
    ").show(50, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bebd1643-2e9c-4041-b027-bc797a55c674",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import instr, col\n",
    "\n",
    "df_estoque.filter(instr(col(\"nome_produto\"), \"  \") > 0).show(50, False)\n",
    "df_estoque.filter(instr(col(\"nome_subproduto\"), \"  \") > 0).show(50, False)\n",
    "df_estoque.filter(instr(col(\"local_fabricacao\"), \"  \") > 0).show(50, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bc02f79f-3f6d-4106-bc08-171175bcdefb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import regexp_replace\n",
    "\n",
    "df_estoque = df_estoque.withColumn(\n",
    "    \"nome_produto\",\n",
    "    regexp_replace(col(\"nome_produto\"), \" +\", \" \")\n",
    ").withColumn(\n",
    "    \"nome_subproduto\",\n",
    "    regexp_replace(col(\"nome_subproduto\"), \" +\", \" \")\n",
    ").withColumn(\n",
    "    \"local_fabricacao\",\n",
    "    regexp_replace(col(\"local_fabricacao\"), \" +\", \" \")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3d72c4fa-5b7a-4aa0-a86d-c823ad561a2b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "df_estoque.filter(\n",
    "    col(\"data_fabricacao\") > col(\"data_validade\")\n",
    ").show(50, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7c6668c9-37cc-409f-945c-33b3199eccc9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_estoque.filter(\n",
    "    col(\"nome_produto\").isNull() |\n",
    "    col(\"nome_subproduto\").isNull() |\n",
    "    col(\"local_fabricacao\").isNull() |\n",
    "    col(\"data_fabricacao\").isNull() |\n",
    "    col(\"data_validade\").isNull()\n",
    ").show(50, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "844635e5-7251-4ab6-b763-5d946838acc7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(df_estoque)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "17f31aa6-45e8-4c46-be5a-171d3901c53b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(df_vendas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9b0cdc6b-de1e-42b8-9e43-f27e2cc9021d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_vendas.select(\"nome_produto\").distinct().show(200, False)\n",
    "df_vendas.select(\"nome_subproduto\").distinct().show(200, False)\n",
    "df_vendas.select(\"local_fabricacao\").distinct().show(200, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "42fff41b-ec81-467e-866e-6ef4d5aa0db1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import trim, col\n",
    "\n",
    "df_vendas = df_vendas.withColumn(\"nome_produto\", trim(col(\"nome_produto\")))\n",
    "df_vendas = df_vendas.withColumn(\"nome_subproduto\", trim(col(\"nome_subproduto\")))\n",
    "df_vendas = df_vendas.withColumn(\"local_fabricacao\", trim(col(\"local_fabricacao\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7bf2f610-293e-4171-af03-c1997d799f41",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import instr\n",
    "\n",
    "df_vendas.filter(instr(col(\"nome_produto\"), \"  \") > 0).show(50, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "561466cc-401c-4a94-a3bd-679e21979b8f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_vendas.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0ff8dbda-5d44-4da8-a590-462a6be52ee4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, to_date\n",
    "\n",
    "df_vendas = spark.table(\"classes.bronze.exceis_vendas\")\n",
    "\n",
    "df_vendas = df_vendas.withColumn(\n",
    "    \"data_validade\",\n",
    "    to_date(col(\"data_validade\"), \"dd/MM/yyyy\")\n",
    ").withColumn(\n",
    "    \"data_fabricacao\",\n",
    "    to_date(col(\"data_fabricacao\"), \"dd/MM/yyyy\")\n",
    ")\n",
    "\n",
    "display(df_vendas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a96d27fc-7cdb-4ed4-a44c-d2b12e8b9e8b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, trim, lower\n",
    "\n",
    "print(\"Processando Produtos...\")\n",
    "# 1. Leitura\n",
    "df_produto = spark.table(\"classes.bronze.exceis_produto\")\n",
    "\n",
    "# 2. Tratamento (Padronizar status para minúsculo e remover espaços)\n",
    "df_produto = df_produto.withColumn(\"status_produto\", lower(trim(col(\"status_produto\")))) \\\n",
    "                       .withColumn(\"nome_marca\", trim(col(\"nome_marca\"))) \\\n",
    "                       .withColumn(\"nome_produto\", trim(col(\"nome_produto\")))\n",
    "\n",
    "display(df_produto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ff70a3ac-f324-4b50-b3a2-3a9bae7e0a77",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display (df_produto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e7e8dc1c-4018-490a-b8ae-bf23e2410f3a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_produto.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "60dad192-27f1-4068-8122-38a4e669cf1c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_produto.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bd124ef6-6296-430f-aeef-5c421dece115",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_produto = spark.sql(\"select * from classes.bronze.exceis_produto\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5061b4e3-7128-4ef8-975a-bd8f421a3241",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_produto.printSchema()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "374fd61b-ceda-4f49-aa8e-01bf929898c8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# --- SALVAMENTO NA CAMADA SILVER ---\n",
    "print(\"Iniciando gravação das tabelas...\")\n",
    "\n",
    "# A opção 'overwriteSchema' é essencial quando mudamos tipos de coluna (ex: Texto -> Data)\n",
    "df_vendas.write.format(\"delta\").mode(\"overwrite\").option(\"overwriteSchema\", \"true\").saveAsTable(\"classes.silver.vendas\")\n",
    "df_estoque.write.format(\"delta\").mode(\"overwrite\").option(\"overwriteSchema\", \"true\").saveAsTable(\"classes.silver.estoque\")\n",
    "df_produto.write.format(\"delta\").mode(\"overwrite\").option(\"overwriteSchema\", \"true\").saveAsTable(\"classes.silver.produtos\")\n",
    "\n",
    "print(\"✅ Sucesso! Camada Silver salva e pronta para a Gold.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "01c0c9f6-1701-40bd-9b71-4366136a4439",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(df_vendas)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 5580948466096850,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "processing_data e",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
